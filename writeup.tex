\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{url}
\usepackage{hyperref}

\title{Luck vs Skill in College Basketball}
\author{Jake Browning, Rohan Mawalkar, Seth Peacock}
\date{November 2024}

\begin{document}

\maketitle

\section{Letter to the Editor}
In addition to this report, write a one-page letter to the newspaper chief editor, explaining the main results of
the report and suggesting findings that can be communicated with the basketball fans reading the newspaper.

\section{Overview}
Describe the problem, your model, results and how your model performed.

\section{Introduction}
% ``Rephrase the problem
% Problems are open-ended and there are many ways to interpret and address them. Explain how you approached the problem."

People love sports because they are a showcase of hard work and talent. People also love sports because they are unpredictable. How do we quantify the effect of one versus the other in a basketball game? On the one hand, we often see this framed as a strict dichotomy between luck and skill: sports outcomes depend in some part on one and in some part on the other. However, careful examination reveals that it is rather unclear where to draw the line between luck and skill. For example, if a team happens to study exactly the right film the night before a big game and is able to perfectly foil the other team's plans, is that luck or is it skill? On the one hand, it certaintly takes skill to study your opponent and use this information to your advantage. On the other hand, they could have easily picked the wrong film to study! Instead, we would like to approach this problem using a dichotomy between certainty and uncertainty.  This also addresses the issue of a lack of data; there are many aspects of ``skill'' (such as individual player records) which require more data than we have been able to gather so far.

Our goal here is twofold: first develop a model which predicts the outcome of a basketball, and second quantify the effect of luck/uncertainty in a basketball game. Since we want to incorporate the effect of uncertainty, our prediction model will contain a stochastic element which we will have to derive. However, we will also discuss additional markers of uncertainty in our data to better understand the effect of uncertainty on a basketball game in a more general sense. 


\section{Methods}
% ``Explain your model
% Clearly state and justify ALL assumptions your model uses
% Motivate your model. Why did you choose your approach?
% Clearly describe your model
% Clearly define all variables
% Include tables and figures to make it easier to understand
% Analyze your model
% What are the strengths and weaknesses of your model?
% How could you test your model? How stable are the results to noise? 
% If you had more time, how would you expand/improve your model''?

Our model will be a modified version of the classic Elo ranking in chess, which we will use along with data from throughout the regular season to assign each team a ranking. (From here on, when we say ``Elo ranking'' we will mean our modified ranking, and will say ``classic Elo ranking'' if we mean the original.) Given a pair of teams, these rankings will be used to give us probabilities of an upset (that is, the probability that the team with the lower Elo rating wins). 


\subsection{Our ``Elo'' Ranking}
Traditionally (see~\cite{mediumRatingSystem}), a player's Elo ranking is updated after each game based on the following formula:

\[
\]

This is essentially performing a stochastic gradient descent for a logistic regression model, where the Elo ratings are the weights of the model~\cite{stmorseStatisticalLearning}. 
However, this score does not take into account the score 

The Elo score after a team's $n+1^{\text{th}}$ game is given by

\[
\gamma_{n+1} = \gamma_n + \alpha\frac{\gamma^{opp}_n}{\gamma_n}\frac{S_{\text{winner}}}{S_{\text{loser}}}
\]
\[
\gamma_{n+1} = \gamma_n - \alpha\frac{\gamma_n}{\gamma^{opp}_n}\frac{S_{\text{winner}}}{S_{\text{loser}}}
\]

where $\gamma_n$ is the team's current Elo score (after week $n$), $\gamma^{opp}_n$ is the opposing team's current Elo score, $\alpha > 0$ is a weight parameter, and $S_{\text{winner}}$, $S_{\text{loser}}$ are the scores of the winner/loser.




We assume that the effect of a homefield advantage is significant, and that it is approximately captured by the average win/loss ratio of home vs away games.
% Jake?
\subsection{Bootstrapping}
We would now like to verify the accuracy of our Elo system. To do this, we ``bootstrap'' \cite{builtinWhatBootstrapping} samples from the regular season games to compare our model's predictions of the probability of an upset to the actual probability of an upset for a given difference in Elo rankings. If our Elo ratings are accurate, we should see these are close to one another.

Note that the probability of an upset obtained via bootstrapping $\hat{p}_U(\Delta_{\text{Elo}})$ could be anything between 0 and 1, while the expected outcome probability from Elo rankings is necessarily between 0 and 1/2. However, we expect that $\hat{p}_U(\Delta_{\text{Elo}})$ should be roughly less than 0 to 1/2, for the same reasons that we hope our Elo expected outcomes $E_U(\Delta_{\text{Elo}})$ are similar to $\hat{p}_U(\Delta_{\text{Elo}})$ for each value of $(\Delta_{\text{Elo}})$. 


To quantify the accuracy of our Elo system, we plot $E_U(\Delta_{\text{Elo}})$ against $\hat{p}_U(\Delta_{\text{Elo}})$, fit a linear regression, and calculate the MSE.  
%(see \autoref{figure}) 

\subsection{Quantifying Uncertainty}
To first order, we now also have two (hopefully similar) ways of quantifying the measure of uncertainty in a basketball game: the expected probability of an upset based on Elo rankings (as a function of the difference in Elo rankings), and the bootstrapped estimate for the probability of an upset (as a function of the difference in Elo rankings). However, there is an additional higher order kind of uncertainty, which is the variance in the bootstrapped sample of games with a given score difference. 
% Is there? for a given set of upsets and non-upsets which gives a particular probability of upset, the variance is going to be fixed, isn't it! (Binomial has fixed variance for a given mean/prob). But maybe there's something else we can do here -- using score differentials?

%ROHAN? Is there another way to interpret the uncertainty here?

\subsection{Weaknesses}

\subsection{Rejected Ideas}
\begin{itemize}
    \item We considered defining the score differential as the absolute value of the difference of the scores. However, this would weight a 20--10 loss as the same as a 90--80 loss, which seems much less accurate to how basketball fans see the game.
    % \item We also considered coming up with a predicted score differential based on our ``Elo'' ratings. Since basketball fans seem to be primarily interested in the probability of an upset (and it's less important how much the upset )
    % \item When calculating the bootstrapped variance, there was the question of what to use as the expected value.
\end{itemize}

\section{Results}
What does your model say about the question you have been given?
In particular, you may consider whether
incorporating the margin of victory in each game can change your model predictions of the contributions of
ability and chance to the sports outcomes. You may also assess how accurately your model could predict the
outcome of the 2024 March Madness Tournament.


\subsection{Verifying Elo Rankings}
Here we plot $E_U(\Delta_{\text{Elo}})$ against $\hat{p}_U(\Delta_{\text{Elo}})$ along with the $y=x$ line. If our Elo system has perfectly captured the expected upset probability, then these points should be close to the $y=x$ line. To measure the inaccuracy, we calculate the mean squared error. 

When updating our ``Elo'' scores, we had an artbitrary parameter $K$. We repeated this process with a range of $K$ and see which one minimizes the MSE; the plot above shows the result of the minimized MSE. The plot below shows the effect of $K$ on the MSE. It is important to note that picking the $K$ we did 
% Jake? Note you'll have to run this from the beginning and getthe expected $$\hat{p}_U$ aagain as well as these depend on the Elo ranking difference categories which weill change with different K.

\subsection{Predicting March Madness 2024}
We would like to see how well our model could have predicted the results of the March Madness 2024 Tournament. To this end, we ran a large number of simulations using our Elo predictions with our predicted chance of upset and seen what percentage of times we correctly predicted the outcome of the tournament.
% JAKE?
% Will require you to get results of the 2024 torunament, which I guess you could just do by hand?
% If this ends up being we NEVER correctly predict it, we could maybe just quantify HOW GOOD we were on average like how many games we predicted correctly.

Of course, due to the uncertainty everyone acknowleges exists, this percentage would be low no matter what. After all, no one has ever correctly guessed the result of the tournament~\cite{cbsnewsAnyoneEver}. However, we note that our model (on average) performed better than chance (which would be $(1/2)^62 \approx 2.17 * 10^{-19}$).

\section{Next Steps}
There are several things we would have liked to check if we had had more time. For one, it would be interesting to explore the effect of overfitting by the choice of $K$. That is, does the value of $K$ which minimized the MSE for the bootstrapping verification also maximize the likelihood of predicting the actual outcome of the tournament? If not, then we should likely look into a different way of picking $K$ (perhaps one which incorporates past data) as this choice seems to have lead to overfitting on the regular season games. 

\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}
